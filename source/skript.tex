\documentclass[11pt,a4paper]{article}
\usepackage{graphicx}
\usepackage[margin=20mm]{geometry}
\usepackage{tabto}
\usepackage{glossaries}

\setlength{\parindent}{0mm}

\makeglossaries

\newglossaryentry{vaddr}
{	
	name={virtual address (vaddr)},
	description={address in process' address space}
}

\newglossaryentry{paddr}
{
	name={physical address (paddr)},
	description={address of real memory}
}

\newglossaryentry{process control block}
{
	name={process control block (PCB)},
	description={Informations about allocated resources of a process}
}

\newglossaryentry{address space}
{
	name={address space (AS)},
	description={Virtrual memory a program can name}}

\begin{document}
	
	\title{OS Zusammenfassung}
	\author{Gr√©goire Mercier}
	
	\maketitle
	
	\begin{abstract}
		This lecture notes are for me to learn LaTeX and review the operating system lecture
	\end{abstract}


	\section{Introduction}
	
	\subsection{Overview}
	
	The Operating System
	
	\begin{itemize}
		\item \textbf{Provides abstraction layer} \newline
		Manages and hides hardware details \newline
		Low-level interfaces to access hardware \newline
		Multiplexes hardware to multiple programs \newline
		makes hardware use effivient for applications
		\item \textbf{Provides protection} from \newline
		users/processes using up all resources \newline
		processes writing into other processes memory \newline
		\item \textbf{is a ressource manager} \newline
		Manages and multiplexes hardware ressources \newline
		Decides between conflicting requests for resource use \newline
		Strives for efficient and fair resource use \newline
		\item \textbf{is a control program} \newline
		Controls execution of programs \newline
		Prevents errors and improper use of the computer
		
	\end{itemize}
	
	There are no universally accepted definitions
	
	\subsection{Hardware}
	
	\textbf{CPU (Central Processing Unit)}
	
	\begin{itemize}
		\item Fetches instructions from memory and executes them
		\item Internal registers store data and metadata during execution
		\item \textbf{User Mode (x86: "Ring 3" or CPL3)} \newline
		Only non-privileged instructions, no hardware managment in this mode for protection
		\item \textbf{Kernel Mode (x86: "Ring 0" or CPL0)} \newline
		All instruction allowed, including privileged instructions \newline
	\end{itemize}
	
	\textbf{RAM (Random Access Memory)} keeps currently execting instructions and data \newline
	
	\textbf{Caching}
	\begin{itemize}
		\item Ram delivers instruction/data slower than the CPU can execute
		\item Memory references typically follow principle of locality
		\item \textbf{Caching} helps mitigating this \textbf{Memory Wall} \newline
		Informations in use are copyed from slower to faster storage. When needed, check whether it is in faster storage before going down in the Memory Hierarchy, then copy it to cache to be used from there
	\end{itemize}
	
	\textbf{Acces times}
	\begin{itemize}
		\item CPU registers					\tab ~1 CPU cycle
		\item L1 cache per core 			\tab ~4 CPU cycles
		\item L2 cache per pair of cores	\tab ~12 CPU cycles
		\item L3 cache						\tab ~28 CPU cycles (~25 GiB/s)
`		\item DDR3-Ram						\tab ~28 CPU cycle for LLC + 50ns (~12 GiB/s)
	\end{itemize}

	\textbf{CPU Cache Organization}
	\begin{itemize}
		\item Caches divided up into cache lines (often 64 bytes each)
		\item Separation of data and instructions in faster caches
		\item \textbf{Cache hit}: Data already in cache
		\item \textbf{Cache miss}: Data has to be fetched from lower level first
		\item Types of Cache misses
		\begin{itemize}
			\item \textbf{Compulsory Miss}: first reference miss, data has never been accessed
			\item \textbf{Capacity Miss}: cache not large enough for Working Set of process
			\item \textbf{Conflict Miss}: cache still has space, but collision due to placement strategy
		\end{itemize}
	\end{itemize}

	\textbf{Device Control}
	
	\begin{itemize}
		\item Device controller accepts command from the OS via device driver
		\item Control by writing into device register and read status by reading it
		\item Data transfer by writing/reading device memory
		\item Port-mapped I/O (PMIO) special CPU instructions to access port-mapped registers and memory
		\item Memory-mapped I/O (MMIO) same address space for Ram and device memory
	\end{itemize}

	\hspace{5mm}Devices can signal the CPU through interrupts
	
	\subsection{OS Invocation}
	
	Operating System Kernel does \textbf{not} always run in the background
	
	Tree occasions invoke the Kernel and switch to kernel-mode
	\begin{itemize}
		\item System calls		\tab User-mode process requires higher privileges
		\item Interrupts		\tab CPU-external device sends a signal
		\item Exceptions		\tab CPU signals an unexpected condition
	\end{itemize}
	
	\textbf{System Calls}
	
	The main Idea behind System calls is the nessecity to protect processes from one another. So processes are running in User-Mode. The OS provides services, which the applications can invoke in System Calls/syscalls, in order to get the action performed by the OS, on behalf of application
	
	Syscall interface between applicateions and OS provides a limited number of well-defined entry points to the kernel
	
	Application Program Interfaces (API) brings another level of abstraction between applications and Programmers (API invokes Syscalls invokes Kernel-Mode operations)
	
	One single entry point to the kernel for all System calls, the \textbf{trap}. Trap switches CPU to kernel mde and enters the kernal in the same, predefined way for every syscall. The system call dispatcher in the kernel acts as a multiplexer for all syscalls.
	
	syscalls identifyed by a number, passed as parameter, \textbf{system call table} maps \textbf{system call number} to kernel funktion, dispatcher decides where to jump based on the number and table.
	
	Programs have the System call number compiled in!
	Never reuse old numbers in future versions of kernel
 	\newline
	
	\textbf{Intrrupts}
	
	Interrupts are used by devices to signal predefined conditions to the OS, they are managed by the Programmable Interrupt Controller. When masked the interrupts are only delivered, when unmasked.
	
	\textbf{interrupt vector}: table pinned in memory containing the adresses of all service routines
	\textbf{interrupt service routine}: takes the control in order to handle a specific interrupt. Saves the state of the interrupted process
	\begin{itemize}
		\item Instruction pointer
		\item Stack pointer
		\item Status word
	\end{itemize}

	
	\textbf{Exceptions}
	\begin{itemize}
		\item Generated by the CPU itself, if an unusual condition makes it impossiible to continue processing
		\item CPU interrupts program and relegate control to the kernel
		\item Kernel determines  the reason for exceptions
		\item If kernel can resolve the problem, it does so and continue the \textbf{faulting instruction}
		\item Otherwise process get killed
	\end{itemize}
	
	Interrupts can happen in \textbf{any} context, Exceptions always occur \textbf{synchronous to} and \textbf{in the context} of a process.
	
	\section{OS Concepts}
	
	Early on, programs were load directly into \textbf{physical memory}. If the program was too large, the  programmer had to manually partition his program into \textbf{overlays}. OS could swap between disk and memory.
	
	Problems: Buggy programs trash other programs, malicious jobs can read other program's operations, Jobs can take all memory for themself,...
	
	\textbf{adress spaces}: every job has his own address space, so they can't reach other jobs adresses. Jobs only use virtual adresses. \newline
	
	\textbf{MMU (memory management unit)}: translates \gls{vaddr} to \gls{paddr}
	
	\begin{itemize}
		\item allows kernel-only virtual addresses
		\item can enforce read-only virtual addresses
		\item can enforce execute disable
	\end{itemize}
	
	Not all addresses need to be mapped at all times. If a virtual address is not mapped, the MMU throws a \textbf{page fault} exception. Handled by loading the faulting address and then continuing the program. \textbf{over-commitment}: more memory than physically aviable. Page faults also issued by MMU on illegal memory access.
	
	A \textbf{process} is a progam in execution, associated with a \gls{process control block} and with a virtual \textbf{address space (AS)}. AS is the only memory a program can name and starts at 0 for every program.
	
	AS are layed out in sections. Memory acces between those sections is illegal and causes a page fault, called \textbf{sementation fault}. Segmentation faults results in the process getting killed by the OS.
	
	A section has the following layout:
	\begin{itemize}
		\item Stack: Function history and local variables
		\item Data: Constatnts, static variables, global variables, strings
		\item Text: Program code
	\end{itemize}
	
	\textbf{Threads} represents execution states of a program
	\begin{itemize}
		\item Instruction pointer (IP) register stores currently executed instruction
		\item Stack pointer (SP) register stores the address of the top of the stack
		\item Program status word (PSW) contains flags about executeion history
		\item ...
	\end{itemize}
	
	Two things to consider when designing an OS:
	
	\textbf{Mechanism}: Implementation of what is done
	
	\textbf{Policy}: The rules which decide when what is done and how much \newline
	
	Operating System need to handle multiple processes and threads in order to provide multi-tasking. The \textbf{scheduler} decides which job to run next, while the \textbf{dispatcher} performs the task-switching. Schedulers provide fairness while trying to reach goals after setted priorities.\newline
	
	Persistent Data is for users is stored in flies and directories. A file is associated with file name and offset with bytes. Directories associate directory names with eigher directory names or file names.
	
	The \textbf{file system} is an ordered collection of blocks, what can be operated on by programmers, with operations like open, read, seek, ...
	
	Processes communicate directly through a special \textbf{named pipe} file
	
	Directories form a \textbf{directory tree/file hierarchy}. The \textbf{root directory} is the topmost directory of a directory tree. Files can be accessed by their \textbf{path name}. \newline
	
	OS abstract the view of information storage to file systems. Drivers hide specific hardware device. OS increases the performance of I/O devices by
	\begin{itemize}
		\item \textbf{Buffering}: Store data temporarily while it is being transferred
		\item \textbf{Caching}: Store parts of data in faster storage for performance
		\item \textbf{Spooling}: Overlap of output of one job with input of other jobs
	\end{itemize}
 	
	\section{Processes}
	
	\subsection{Process Abstraction}
	
	Multiprogramming is the art of switching quickly between processes. Every process is processed in his own "virtual CPU". When switching processes, the execution context changes. On a  \textbf{context switch}, the dispatcher saves the current register and memory mappings and restores those of the next process.
	
	A program is a policy, the process is a mechanism.
	
	With n processes with a process spending p of his time waiting for I/O to complete, then CPU utilization = 1 - ${p^n}$. \newline
	
	\textbf{Concurrency}: Multiple processes on the same CPU
	
	\textbf{Parallelism}: Processes truly rnning at the same time with multiple CPUs
	
	\section{Address Spaces}
	
	Programs can see more memory than aviable (80/20 rule: 80\% of the process memory idle, 20\% active working set). Keep working set in RAM, rest on disk.
	
	\textbf{address space layout}: Organization of code, data and state within process
	Data can be \textbf{fixed sized}, \textbf{free'd in reverse order of allocation} or \textbf{allocated and free'd dynamically}
	
	The \textbf{loader} determines based on an executable file how an executed program is placed in memory \newline
	
	\textbf{Fixed-size Data and Code Segments}
	\begin{itemize}
		\item Data in a program, what has static size, allocated when process created
		\item BSS Segment  (Block Started by Symbol) contains statically-allocated variables and not initialized variabels. The executable file contains the starting address and size of BSS, the entire segment is initially zero
		\item Data segment contains fixed-size, initialized data elements such as global variables
		\item Read-only data segment contains constant numbers and strings
		\item Sometimes BSS, data, and read-only data segment are summarized as a single data segment
	\end{itemize}
	
	\textbf{Stack Segment} \newline
	Data is naturally free'd in reverse order of allocation. Fixed starting point of segment, store top at latest allocation SP (stack pointer). In current CPU, the stack segment typically grows downwards!	\newline
	
	\textbf{Heap Segment}
	Some data needs to be allocated and free'd dynamically "at random", such as input/output, size of edited text, ... \newline
	Allocate memory in two tiers: \newline
	1. Allocate large chunk of memory (heap segment) fom OS, like stack allocation; base address + break pointer (BRK), process can change size by setting BRK \newline
	2. Dynamically partition large chunk into smaller allocation dynamically, with \textit{malloc} and \textit{free}. This happens purely in user space!
	
	\subsection{Typical Process Address Space Layout}
	\begin{itemize}
		\item \textbf{OS}				\tab Adresses where the kernel is mapped 0xFFFFFFFF
		\item \textbf{Stack}		 	\tab Local variables, function call parameters, return addresses
		\item \textbf{Heap}				\tab Dynamically allocated data (malloc)
		\item \textbf{BSS}				\tab Uninitialized local variables dclared as static
		\item \textbf{Data}				\tab Initialized data, global variables
		\item \textbf{RO-Data}		\tab Read-only data, strings
		\item \textbf{Text}				\tab Program, machine code
	\end{itemize}


	\section{Threads}
	In traditional OS, each process has it's own address space, set of allocated resources and one thread of execution. \newline
	Modern OS handle the processes and treads of execution more flexibly. Processe provide the abstraction of an AS and address resources, while threads provide the abstraction for execution state of that AS/container. /par
	Why using multiple Threads? \newline
	So programs can handle many tasks at once. Without threads, some of the tasks could block each other. Many sequential threads are more easy to handle.
	It depents on what is to be done in order to choose between threads and processes. If processes share data, they do it explizitly. Threads allow multiple tasks at once in a single process.
	
	\subsection{Thread Libraries}
	Provide an API for creating and managing threads. Pthreads is the POSIX API for creation and synchronization. It specifies behaviour of the thread library.
	
	Each \textbf{Pthread} is associated with an identifier (Thread ID(TID)), a set of registers (including IP and SP) and a stack area holding the execution state of that thread.
	
	\begin{itemize}
		\item Pthread\_create Create a new thread, passing pointer to pthread\_t (holding TID after successful call), attributes, start funcition and arguments, returning 0 on success or error value.
		\item Pthread\_exit Terminate the calling thread, passing exit code, freeing ressources
		\item Pthread\_join Wait for a specific thread to exit, passing pthread\_t to wait for (or -1 for any thread), pointer to pointer for exit code, returning 0 on success, otherwise error value
		\item Pthread\_yield Release the CPU to let another thread run
	\end{itemize}

	Multithreaded programming is challenging, because there is more shared state than with processes, so more can possibly go wrong. Programmer needs to care about dividing, ordering, and balancing activities, dividing data and synchronize access to shared data.
	
	Processes group resources, threads encapsulate execution. There is a need to differentiate between
	\begin{itemize}
		\item \textbf{Process Control Block (PCB)}: Information needed to implement processes eg. Adress space, open file, child processes, pending alarms. \newline
		The PCB is always known to the OS
		\item \textbf{Thread control Block (TCB)}: Per thread data, eg IP, Registers, Stack, state. Depending on thread model the OS knows about threads or not.
 	\end{itemize}
 
	\subsection{Thread Model Overviev}
	
	OS always knows of at least one thread per process. Threads that are known to the OS are called kernel threads. Threads that are known to the process are called user threads.
	
	\begin{itemize}
		\item \textbf{Many-to-One Model}/Threads fully implemented in user-space: Kernel knows only knows one of possibly multiple threads, user threads are called \textbf{User Level Threads(ULT)}
		\item \textbf{One-to-One Model}/Kernel fully aware of and responsible for managing threads: Each user thread maps to a kernel thread, user threads are called \textbf{Kernel Level Thread(KLT)}
		\item \textbf{M-to-N Model}:Kernel knows some threads per process, but others are known only to the process, flexible mappint of user threads to less kernel threads. Known as hybrid thread model.
	\end{itemize}
	
	
	\textbf{Many-to-One Model: User Level Threads (ULT)} \newline
	The kernel only manages the process, multiple threads are unknown to the kernel. That allows faster thread management operations, a more flexible scheduling policy, fewer system resources and cen be even used when OS does not support threads. But there is no parallel execution possible and if only one thread blocks, the entire process blocks. Also it is needed to reimlement parts of the OS. Linux defines some acitons as followed: \textbf{mkcontext\_t} and \textbf{ucontext\_t} to keep thread state, \textit{makecontext} (initialize a new context), \textit{getcontext} (store currently active context), \textit{setcontext} (replace current context with different one), \textit{swapcontext} (user-level context switching between threads). Periodic threadswitching can be implemented using a \textbf{SIGALRM} exception handler.
	
	Address Space Layout: The "main" part of the \textbf{Stack} is known to OS and is used by thread library. The own execution state for every thread is allocated dynamically on the heap, using \textit{malloc}. There is possibly an own stack for each exception handler. Concurrent \textbf{heap} possible. \newline
	
	\textbf{One-to-One Model: Kernel Threads (KLT)} \newline
	The kernel knows and manages every thread, making real paralellism and individual thread block possible. On the downside, the OS manages every thread in the system, syscalls are needed for thread management and scheduling is fixed in OS.
	
	Address Space Layout: There is an own execution state ($\equiv$\textbf{stack}). Possibly own stack for each exception handler. Parallel \textbf{heap} use is possible, but not all heaps are thread-safe.
	
	Implementation and issues: all thread management data is stored in kernel, management funcions provided as syscalls. Signals are used in UNIX to notify a process that a particular event has occured. The signal handler can run on the process stack, on a stack dedicated to a specific signal handler or a a stack dedicated to all signals. \newline
	
	\textbf{M-to-M Model: Hybrid Threads} \newline
	M ULTs are mapped to (at most) N KLTs, using pros of ULT and KLT: non-blocking with quick management. Provides flexible scheduling policiy and efficient execution, but is hard to implement and to debug.
	
	Implementation: Kernel is not involved in thread activities such as \textit{create} and \textit{join}. Reached by mapping multiple ULTs on each KLT, so when a ULT blocks, the user-space run-time system run a different ULT without switching to the kernel. \textbf{Upcalls}: Kernel notices, that a thread will block and sends a signal to the process. Upcall notifies the process of the thread id and event that happened. Exception handler of the process shedule a different thread in that process. Kernel later informs the process that the blocking event has finished via antother upcall.
	
	
	\newpage
	
	\printglossaries
	
	
	
\end{document}